{"cells": [{"cell_type": "markdown", "id": "68182d96-0b09-4e58-ae38-915313f6317b", "metadata": {}, "source": ["![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2F05+-+TensorFlow&dt=05Tools+-+Automation.ipynb)\n", "\n", "# 05Tools - Automation\n", "\n", "# IN ACTIVE DEVELOPMENT\n", "\n", "<p align=\"center\" width=\"100%\">\n", "    <img src=\"../architectures/overview/automation.png\" width=\"100%\">\n", "</p>\n", "    \n", "This notebook will focus on some helpful GCP tools for automation. In Vertex AI, Training Jobs and Pipelines are triggered to run with the Vertex AI Client library:\n", "\n", "- [Python Cloud Client Libraries](https://cloud.google.com/python/docs/reference)\n", "    - [google-cloud-aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest)\n", "        - [`aiplatform` package](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform)\n", "            - Training Jobs\n", "                - [`aiplatform.CustomJob.from_local_script()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_from_local_script)\n", "                    - 05a, Using a Python Script\n", "                - [`aiplatform.CustomJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob)\n", "                    - with [worker_pool_specs](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.WorkerPoolSpec) using `python_package_spec`\n", "                    - 05b, Using a Python Source Distribution\n", "                - [`aiplatform.CustomJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob)\n", "                    - with [worker_pool_specs](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.WorkerPoolSpec) using `container_spec`\n", "                    - 05c, Using a Custom Container\n", "                - [`aiplatform.CustomTrainingJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob#google_cloud_aiplatform_CustomTrainingJob)\n", "                    - 05d, Using a Python Script\n", "                - [`aiplatform.CustomPythonPackageTrainingJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomPythonPackageTrainingJob)\n", "                    - 05e, Using a Python Source Distribution\n", "                - [`aiplatform.CustomContainerTrainingJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomContainerTrainingJob#google_cloud_aiplatform_CustomContainerTrainingJob)\n", "                    - 05f, Using a Custom Container\n", "                - Hyperparameter Tuning Job:\n", "                    - [`aiplatform.HyperparameterTuningJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.HyperparameterTuningJob#google_cloud_aiplatform_HyperparameterTuningJob)\n", "                    - In 05g, 05h, and 05i\n", "            - Pipelines\n", "                - [`aiplatform.PipelineJob`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob)\n", "                \n", "This notebook will show using a Python Function to trigger jobs with the SDK summarized above.  The function will be run in a Cloud Function.  Functions are triggered, in this case triggering will be done with a Cloud Pub/Sub Topic.  Message will be sent to the Pub/Sub topic manually and on a schedule by using Cloud Scheduler.\n", "\n", "**Prerequisites:**\n", "- 05f\n", "\n", "**Resources:**\n", "- Documentation\n", "    - [Schedule pipeline exectuion with Cloud Scheduler](https://cloud.google.com/vertex-ai/docs/pipelines/schedule-cloud-scheduler#create_a_cloud_function_with_http_trigger)\n", "    - [Trigger a pipeline run with Pub/Sub](https://cloud.google.com/vertex-ai/docs/pipelines/trigger-pubsub)\n", "\n", "**Conceptual Flow & Workflow**\n", "                \n"]}, {"cell_type": "markdown", "id": "2dab1250-c3f2-4993-abff-7b168ac12d3a", "metadata": {}, "source": ["---\n", "## Setup"]}, {"cell_type": "markdown", "id": "1b890077-eca9-46bd-80d1-fb5791b17fc6", "metadata": {}, "source": ["### Package Installs (if needed)\n", "\n", "This notebook uses the Python Clients for\n", "- Google Service Usage\n", "    - to enable APIs (Artifact Registry and Cloud Build)\n", "- Artifact Registry\n", "    - to create repositories for Python packages and Docker containers\n", "- Cloud Pub/Sub\n", "- Cloud Functions\n", "- Cloud Scheduler\n", "\n", "The cells below check to see if the required Python libraries are installed.  If any are not it will print a message to do the install with the associated pip command to use.  These installs must be completed before continuing this notebook."]}, {"cell_type": "code", "execution_count": 1, "id": "2d33d0e3-5087-4390-bac3-37cb86322725", "metadata": {}, "outputs": [], "source": ["try:\n", "    import google.cloud.service_usage_v1\n", "except ImportError:\n", "    print('You need to pip install google-cloud-service-usage')\n", "    !pip install google-cloud-service-usage -q"]}, {"cell_type": "code", "execution_count": 2, "id": "b0912cc9-83c1-47be-ba26-dc5a4bfc9662", "metadata": {}, "outputs": [], "source": ["try:\n", "    import google.cloud.pubsub\n", "except ImportError:\n", "    print('You need to pip install google-cloud-pubsub')\n", "    !pip install google-cloud-pubsub -q"]}, {"cell_type": "code", "execution_count": 3, "id": "4b7f54ff-a276-4e42-b5e4-4a9438b325fe", "metadata": {}, "outputs": [], "source": ["try:\n", "    import google.cloud.functions\n", "except ImportError:\n", "    print('You need to pip install google-cloud-functions')\n", "    !pip install google-cloud-functions -q"]}, {"cell_type": "code", "execution_count": 4, "id": "b6161f09-7dc4-4d58-88ba-1122e141c23c", "metadata": {}, "outputs": [], "source": ["try:\n", "    import google.cloud.scheduler\n", "except ImportError:\n", "    print('You need to pip install google-cloud-scheduler')\n", "    !pip install google-cloud-scheduler -q"]}, {"cell_type": "markdown", "id": "8892f847-a305-4108-b415-9a551d860de2", "metadata": {}, "source": ["### Environment"]}, {"cell_type": "markdown", "id": "96d92af7-fb7d-48c7-85f3-68ddac43a229", "metadata": {}, "source": ["inputs:"]}, {"cell_type": "code", "execution_count": 5, "id": "06a4092d-c650-497f-9d17-9758fb52a0f5", "metadata": {}, "outputs": [{"data": {"text/plain": ["'statmike-mlops-349915'"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["project = !gcloud config get-value project\n", "PROJECT_ID = project[0]\n", "PROJECT_ID"]}, {"cell_type": "code", "execution_count": 6, "id": "f57aaa40-39aa-4a52-b6d9-c3c7fa7419f8", "metadata": {}, "outputs": [], "source": ["REGION = 'us-central1'\n", "EXPERIMENT = 'automation'\n", "SERIES = '05'"]}, {"cell_type": "markdown", "id": "bbec30a9-37fc-4d5f-bf31-29ccd3aa7ec6", "metadata": {}, "source": ["packages:"]}, {"cell_type": "code", "execution_count": 7, "id": "45f6221e-965f-413e-bc04-728d4f7bb521", "metadata": {}, "outputs": [], "source": ["from google.cloud import aiplatform\n", "from datetime import datetime\n", "import pkg_resources\n", "from IPython.display import Markdown as md\n", "from google.cloud import service_usage_v1\n", "from google.cloud import artifactregistry_v1\n", "from google.cloud import pubsub_v1\n", "from google.cloud import functions_v1\n", "from google.cloud import scheduler_v1\n", "#from google.cloud\n", "#from google.cloud\n", "from google.cloud import storage\n", "from google.cloud import bigquery\n", "from google.protobuf import json_format\n", "from google.protobuf.struct_pb2 import Value\n", "from google.protobuf.duration_pb2 import Duration\n", "import json\n", "import os\n", "import shutil\n", "import zipfile\n", "import numpy as np\n", "import pandas as pd"]}, {"cell_type": "markdown", "id": "de80f037-c80d-4a93-a357-a7626a658db6", "metadata": {}, "source": ["clients:"]}, {"cell_type": "code", "execution_count": 8, "id": "fdef886a-3841-4124-a4ae-72a8977433ed", "metadata": {}, "outputs": [], "source": ["gcs = storage.Client()\n", "su_client = service_usage_v1.ServiceUsageClient()\n", "pubsub_pubclient = pubsub_v1.PublisherClient() \n", "functions_client = functions_v1.CloudFunctionsServiceClient()\n", "scheduler_client = scheduler_v1.CloudSchedulerClient()"]}, {"cell_type": "markdown", "id": "a3abf4be-ebdb-442e-ae48-09dd5f626e69", "metadata": {}, "source": ["parameters:"]}, {"cell_type": "code", "execution_count": 9, "id": "29c66ff7-dfd4-469e-b669-8386ecfced6f", "metadata": {}, "outputs": [], "source": ["DIR = f\"temp/{EXPERIMENT}\""]}, {"cell_type": "code", "execution_count": 10, "id": "479db5db-1fd3-4f3c-96fe-67576c26a674", "metadata": {}, "outputs": [{"data": {"text/plain": ["'1026793852137-compute@developer.gserviceaccount.com'"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n", "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n", "SERVICE_ACCOUNT"]}, {"cell_type": "markdown", "id": "1b43610c-deb2-466d-88e7-31bb9d167a0b", "metadata": {}, "source": ["List the service accounts current roles:"]}, {"cell_type": "code", "execution_count": 11, "id": "9329f141-f9b9-4b38-b4dc-51b8d7b7b22d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["ROLE\n", "roles/bigquery.admin\n", "roles/owner\n", "roles/run.admin\n", "roles/storage.objectAdmin\n"]}], "source": ["!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""]}, {"cell_type": "markdown", "id": "d3ecdea7-880c-4b8f-85b1-67577ec56e5e", "metadata": {}, "source": [">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."]}, {"cell_type": "markdown", "id": "a5d74254-2a9b-4b81-a8d2-2fc9a1f9ebcf", "metadata": {}, "source": ["environment:"]}, {"cell_type": "code", "execution_count": 12, "id": "876379dc-dc1a-4dd2-87ac-1c9cc9c83afa", "metadata": {}, "outputs": [], "source": ["!rm -rf {DIR}\n", "!mkdir -p {DIR}"]}, {"cell_type": "markdown", "id": "23546439-e545-481d-811f-a61a765677b4", "metadata": {"tags": []}, "source": ["### Enable APIs\n", "\n", "Using Cloud Functions, Cloud Pub/Sub and Cloud Scheduler requires enabling these APIs for the Google Cloud Project.\n", "\n", "Options for enabeling these.  In this notebook option 2 is used.\n", " 1. Use the APIs & Services page in the console: https://console.cloud.google.com/apis\n", "     - `+ Enable APIs and Services`\n", "     - Search for Cloud Build and Enable\n", "     - Search for Artifact Registry and Enable\n", " 2. Use [Google Service Usage](https://cloud.google.com/service-usage/docs) API from Python\n", "     - [Python Client For Service Usage](https://github.com/googleapis/python-service-usage)\n", "     - [Python Client Library Documentation](https://cloud.google.com/python/docs/reference/serviceusage/latest)\n", "     \n", "The following code cells use the Service Usage Client to:\n", "- get the state of the service\n", "- if 'DISABLED':\n", "    - Try enabling the service and return the state after trying\n", "- if 'ENABLED' print the state for confirmation"]}, {"cell_type": "markdown", "id": "cb723e18-09c7-472d-b07b-27ac785efa4c", "metadata": {}, "source": ["#### Cloud Pub/Sub"]}, {"cell_type": "code", "execution_count": 13, "id": "e8dc2b31-84d3-4a1f-b726-e549a13d7543", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Cloud Pub/Sub already enabled for project: statmike-mlops-349915\n"]}], "source": ["pubsub = su_client.get_service(\n", "    request = service_usage_v1.GetServiceRequest(\n", "        name = f'projects/{PROJECT_ID}/services/pubsub.googleapis.com'\n", "    )\n", ").state.name\n", "\n", "\n", "if pubsub == 'DISABLED':\n", "    print(f'Cloud Pub/Sub is currently {pubsub} for project: {PROJECT_ID}')\n", "    print(f'Trying to Enable...')\n", "    operation = su_client.enable_service(\n", "        request = service_usage_v1.EnableServiceRequest(\n", "            name = f'projects/{PROJECT_ID}/services/pubsub.googleapis.com'\n", "        )\n", "    )\n", "    response = operation.result()\n", "    if response.service.state.name == 'ENABLED':\n", "        print(f'Cloud Pub/Sub is now enabled for project: {PROJECT_ID}')\n", "    else:\n", "        print(response)\n", "else:\n", "    print(f'Cloud Pub/Sub already enabled for project: {PROJECT_ID}')"]}, {"cell_type": "markdown", "id": "b4e894c8-2b1a-44d2-b8e5-b6cb7e1a553f", "metadata": {}, "source": ["#### Cloud Functions"]}, {"cell_type": "code", "execution_count": 14, "id": "79c3fe1c-f7df-4acb-b1f5-e234d9d3385c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Cloud Functions already enabled for project: statmike-mlops-349915\n"]}], "source": ["cloudfunctions = su_client.get_service(\n", "    request = service_usage_v1.GetServiceRequest(\n", "        name = f'projects/{PROJECT_ID}/services/cloudfunctions.googleapis.com'\n", "    )\n", ").state.name\n", "\n", "\n", "if cloudfunctions == 'DISABLED':\n", "    print(f'Cloud Functions is currently {cloudfunctions} for project: {PROJECT_ID}')\n", "    print(f'Trying to Enable...')\n", "    operation = su_client.enable_service(\n", "        request = service_usage_v1.EnableServiceRequest(\n", "            name = f'projects/{PROJECT_ID}/services/cloudfunctions.googleapis.com'\n", "        )\n", "    )\n", "    response = operation.result()\n", "    if response.service.state.name == 'ENABLED':\n", "        print(f'Cloud Functions is now enabled for project: {PROJECT_ID}')\n", "    else:\n", "        print(response)\n", "else:\n", "    print(f'Cloud Functions already enabled for project: {PROJECT_ID}')"]}, {"cell_type": "markdown", "id": "6cd005c8-5b2a-4b43-bcf3-17f328e43130", "metadata": {}, "source": ["#### Cloud Scheduler"]}, {"cell_type": "code", "execution_count": 15, "id": "d4a70572-e1b1-485f-802d-db7a67ad5379", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Cloud Scheduler already enabled for project: statmike-mlops-349915\n"]}], "source": ["cloudscheduler = su_client.get_service(\n", "    request = service_usage_v1.GetServiceRequest(\n", "        name = f'projects/{PROJECT_ID}/services/cloudscheduler.googleapis.com'\n", "    )\n", ").state.name\n", "\n", "\n", "if cloudscheduler == 'DISABLED':\n", "    print(f'Cloud Scheduler is currently {cloudscheduler} for project: {PROJECT_ID}')\n", "    print(f'Trying to Enable...')\n", "    operation = su_client.enable_service(\n", "        request = service_usage_v1.EnableServiceRequest(\n", "            name = f'projects/{PROJECT_ID}/services/cloudscheduler.googleapis.com'\n", "        )\n", "    )\n", "    response = operation.result()\n", "    if response.service.state.name == 'ENABLED':\n", "        print(f'Cloud Scheduler is now enabled for project: {PROJECT_ID}')\n", "    else:\n", "        print(response)\n", "else:\n", "    print(f'Cloud Scheduler already enabled for project: {PROJECT_ID}')"]}, {"cell_type": "markdown", "id": "115c4dc6-4e9a-47fa-92c7-8b64313c056c", "metadata": {"tags": []}, "source": ["---\n", "## Pub/Sub\n", "\n", "The main concepts:\n", "- Topic - a feed of messages\n", "     - Publish - send a new message to a topic\n", "     - Subscription - receive messages that arrive on topic\n", "          - Push - the subscriber has new messages pushed to it\n", "          - Pull - the subscriber request new messages by pulling them\n", "          \n", "In this example, a topic will be set up for training the model in the local `EXPERIMENT`.  Publishing a new message to this topic will trigger a training run initiated by the Cloud Function (setup below).  The Cloud Funtion will have a push subscription to the topic."]}, {"cell_type": "code", "execution_count": 16, "id": "cce2f700-99e2-4d62-af4f-ea8452900ae2", "metadata": {}, "outputs": [], "source": ["PUBSUB_TOPIC = f'train-{SERIES}-{EXPERIMENT}'"]}, {"cell_type": "code", "execution_count": 17, "id": "a2db1eee-d3ec-4a42-8d0c-cae0fa12bd86", "metadata": {}, "outputs": [], "source": ["for topic in pubsub_pubclient.list_topics(project = f'projects/{PROJECT_ID}'):\n", "    if topic.name.endswith(PUBSUB_TOPIC):\n", "        break\n", "    else: topic = ''"]}, {"cell_type": "code", "execution_count": 69, "id": "97815443-b095-4554-a300-04f7ad6f294c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["name: \"projects/statmike-mlops-349915/topics/train-05-automation\"\n", "\n"]}], "source": ["if topic:\n", "    print(topic)\n", "else:\n", "    topic = pubsub_pubclient.create_topic(\n", "        name = pubsub_pubclient.topic_path(PROJECT_ID, PUBSUB_TOPIC)\n", "    )\n", "    print(topic)"]}, {"cell_type": "markdown", "id": "22f81ede-fe92-4c8c-8980-85fefefbd6f3", "metadata": {}, "source": ["---\n", "## Cloud Functions"]}, {"cell_type": "markdown", "id": "20cb5495-c2fa-4e47-ab47-9146c412b0eb", "metadata": {}, "source": ["### Create Files for Function"]}, {"cell_type": "code", "execution_count": 20, "id": "2881207e-272c-4487-81df-2ee3d49ff025", "metadata": {}, "outputs": [], "source": ["if os.path.exists(f'{DIR}/function'): shutil.rmtree(f'{DIR}/function')\n", "os.makedirs(f'{DIR}/function')"]}, {"cell_type": "code", "execution_count": 21, "id": "439f5cfc-744f-4734-ac62-f1fba50e5041", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Writing temp/automation/function/main.py\n"]}], "source": ["%%writefile {DIR}/function/main.py\n", "\n", "# packages\n", "import base64\n", "import json\n", "from google.cloud import aiplatform\n", "from datetime import datetime\n", "\n", "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n", "\n", "# function that runs the code from the 05f notebook with inputs\n", "def train(event, context):\n", "    #Triggered from a message on a Cloud Pub/Sub topic.\n", "    \n", "    # decode the data input from the event dictionary and convert to Python dictionary\n", "    function_input = json.loads(base64.b64decode(event['data']).decode('utf-8'))\n", "    print(function_input)\n", "    \n", "    # INPUTS\n", "    EPOCHS = function_input['EPOCHS']\n", "    BATCH_SIZE = function_input['BATCH_SIZE']\n", "    VAR_TARGET = function_input['VAR_TARGET']\n", "    VAR_OMIT = function_input['VAR_OMIT']\n", "    PROJECT_ID = function_input['PROJECT_ID']\n", "    BQ_PROJECT = function_input['BQ_PROJECT']\n", "    BQ_DATASET = function_input['BQ_DATASET']\n", "    BQ_TABLE = function_input['BQ_TABLE']\n", "    REGION = function_input['REGION']\n", "    EXPERIMENT = function_input['EXPERIMENT']\n", "    SERIES = function_input['SERIES']\n", "    EXPERIMENT_NAME = function_input['EXPERIMENT_NAME']\n", "    RUN_NAME = f'run-{TIMESTAMP}'\n", "    TRAIN_COMPUTE = function_input['TRAIN_COMPUTE']\n", "    DEPLOY_IMAGE = function_input['DEPLOY_IMAGE']\n", "    URI = function_input['URI']\n", "    REPOSITORY = function_input['REPOSITORY']\n", "    SERVICE_ACCOUNT = function_input['SERVICE_ACCOUNT']\n", "    \n", "    # clients\n", "    aiplatform.init(project = PROJECT_ID, location = REGION)\n", "    \n", "    # Get Vertex AI Experiment Tensorboard Instance Name\n", "    tb = aiplatform.Tensorboard.list(filter=f\"labels.series={SERIES}\")\n", "    if tb:\n", "        tb = tb[0]\n", "    else: \n", "        tb = aiplatform.Tensorboard.create(display_name = SERIES, labels = {'series' : f'{SERIES}'})\n", "    \n", "    # Setup Vertex AI Experiment\n", "    aiplatform.init(experiment = EXPERIMENT_NAME, experiment_tensorboard = tb.resource_name)\n", "    \n", "    # Setup Training Job\n", "    CMDARGS = [\n", "        \"--epochs=\" + str(EPOCHS),\n", "        \"--batch_size=\" + str(BATCH_SIZE),\n", "        \"--var_target=\" + VAR_TARGET,\n", "        \"--var_omit=\" + VAR_OMIT,\n", "        \"--project_id=\" + PROJECT_ID,\n", "        \"--bq_project=\" + BQ_PROJECT,\n", "        \"--bq_dataset=\" + BQ_DATASET,\n", "        \"--bq_table=\" + BQ_TABLE,\n", "        \"--region=\" + REGION,\n", "        \"--experiment=\" + EXPERIMENT,\n", "        \"--series=\" + SERIES,\n", "        \"--experiment_name=\" + EXPERIMENT_NAME,\n", "        \"--run_name=\" + RUN_NAME\n", "    ]\n", "\n", "    trainingJob = aiplatform.CustomContainerTrainingJob(\n", "        display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n", "        container_uri = f\"{REPOSITORY}/{EXPERIMENT}_trainer\",\n", "        model_serving_container_image_uri = DEPLOY_IMAGE,\n", "        staging_bucket = f\"{URI}/models/{TIMESTAMP}\",\n", "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n", "    ) \n", "    \n", "    # Run Training Job AND Upload The Model\n", "    modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n", "\n", "    upload_model = True\n", "    if modelmatch:\n", "        print(\"Model Already in Registry:\")\n", "        if RUN_NAME in modelmatch[0].version_aliases:\n", "            print(\"This version already loaded, no action taken.\")\n", "            upload_model = False\n", "            model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n", "        else:\n", "            print('Loading model as new default version.')\n", "            parent_model = modelmatch[0].resource_name\n", "    else:\n", "        print('This is a new model, creating in model registry')\n", "        parent_model = ''\n", "\n", "    if upload_model:\n", "        model = trainingJob.run(\n", "            model_display_name = f'{SERIES}_{EXPERIMENT}',\n", "            model_labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'},\n", "            model_id = f'model_{SERIES}_{EXPERIMENT}',\n", "            parent_model = parent_model,\n", "            is_default_version = True,\n", "            model_version_aliases = [RUN_NAME],\n", "            model_version_description = RUN_NAME,\n", "            base_output_dir = f\"{URI}/models/{TIMESTAMP}\",\n", "            service_account = SERVICE_ACCOUNT,\n", "            args = CMDARGS,\n", "            replica_count = 1,\n", "            machine_type = TRAIN_COMPUTE,\n", "            accelerator_count = 0,\n", "            tensorboard = tb.resource_name\n", "        )\n", "    \n", "    # THIS FUNCTION WILL TIMEOUT BEFORE IT CAN RUN THE FOLLOWING\n", "    # CONSIDER A SEPERATE FUNCTION THAT IS TRIGGER BY A MODEL REGISTY UPDATE\n", "    \n", "    # Vertex AI Experiment Update and Review\n", "    expRun = aiplatform.ExperimentRun(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)\n", "    expRun.log_params({\n", "        'model.uri': model.uri,\n", "        'model.display_name': model.display_name,\n", "        'model.name': model.name,\n", "        'model.resource_name': model.resource_name,\n", "        'model.version_id': model.version_id,\n", "        'model.versioned_resource_name': model.versioned_resource_name,\n", "        'customJobs.display_name': customJob.display_name,\n", "        'customJobs.resource_name': customJob.resource_name,\n", "        'customJobs.link': job_link,\n", "        'customJobs.tensorboard': board_link\n", "    })\n", "    expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"]}, {"cell_type": "code", "execution_count": 22, "id": "4b4fae4c-1703-485a-af12-04e466d0cdc3", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Writing temp/automation/function/requirements.txt\n"]}], "source": ["%%writefile {DIR}/function/requirements.txt\n", "pandas\n", "google-cloud-aiplatform"]}, {"cell_type": "markdown", "id": "9ac6b1ed-383e-42d2-9daf-39e64e10aaeb", "metadata": {}, "source": ["### Store Files in Cloud Storage\n", "\n", "Copy from local folder (`DIR/function`) to GCS at the path `SERIES/EXPERIMENT/function`:"]}, {"cell_type": "code", "execution_count": 23, "id": "25a93ddf-adb9-4f9f-b6c0-4cc7faa9f822", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["main.py  requirements.txt\n"]}], "source": ["!ls {DIR}/function"]}, {"cell_type": "code", "execution_count": 24, "id": "aae18409-9466-4884-a912-ed3324f3d311", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["main.py\n", "requirements.txt\n"]}], "source": ["!cd {DIR}/function && tar czvf function.tar.gz main.py requirements.txt"]}, {"cell_type": "code", "execution_count": 25, "id": "4ef013f2-eb74-4648-b77e-064ac28b2cd2", "metadata": {}, "outputs": [], "source": ["with zipfile.ZipFile(f'{DIR}/function/function.zip', mode = 'w') as archive:\n", "    archive.write(f'{DIR}/function/main.py', 'main.py')\n", "    archive.write(f'{DIR}/function/requirements.txt', 'requirements.txt')"]}, {"cell_type": "code", "execution_count": 26, "id": "b5730588-87a2-469f-b94d-79840250b0e0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["function.tar.gz  function.zip  main.py\trequirements.txt\n"]}], "source": ["!ls {DIR}/function"]}, {"cell_type": "code", "execution_count": 27, "id": "5e325410-b2d3-4057-9776-d3967a940ed0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["File Name                                             Modified             Size\n", "main.py                                        2022-11-01 22:39:20         5206\n", "requirements.txt                               2022-11-01 22:39:22           31\n"]}], "source": ["with zipfile.ZipFile(f'{DIR}/function/function.zip', mode = 'r') as zip:\n", "    zip.printdir()"]}, {"cell_type": "code", "execution_count": 28, "id": "f6521b22-1ad1-4b40-9310-bc5530a31f04", "metadata": {}, "outputs": [], "source": ["bucket = gcs.lookup_bucket(PROJECT_ID)\n", "SOURCEPATH = f'{SERIES}/{EXPERIMENT}/function'"]}, {"cell_type": "code", "execution_count": 29, "id": "fedac056-7f51-45a1-99f3-f4505e8c1e72", "metadata": {}, "outputs": [], "source": ["blob = bucket.blob(f'{SOURCEPATH}/function.zip')\n", "blob.upload_from_filename(f'{DIR}/function/function.zip')"]}, {"cell_type": "code", "execution_count": 30, "id": "bb660c52-dabd-40ce-9b48-a428c62fb4bc", "metadata": {}, "outputs": [{"data": {"text/plain": ["[<Blob: statmike-mlops-349915, 05/automation/function/function.zip, 1667342376889481>]"]}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": ["list(bucket.list_blobs(prefix = f'{SOURCEPATH}'))"]}, {"cell_type": "code", "execution_count": 31, "id": "7c682d2e-5c6d-45da-9e5e-1e7de0bab73d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["View the bucket directly here:\n", "https://console.cloud.google.com/storage/browser/statmike-mlops-349915/05/automation/function;tab=objects&project=statmike-mlops-349915\n"]}], "source": ["print(f\"View the bucket directly here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID}/{SOURCEPATH};tab=objects&project={PROJECT_ID}\")"]}, {"cell_type": "markdown", "id": "ae8e0bbd-1e03-4739-96c5-3eb1b717298b", "metadata": {}, "source": ["### Create (or Update) Cloud Function"]}, {"cell_type": "code", "execution_count": null, "id": "5bfb0f31-688a-4534-a6f6-8346f28eb819", "metadata": {}, "outputs": [], "source": ["function_name = f'train-{SERIES}-{EXPERIMENT}'"]}, {"cell_type": "code", "execution_count": 45, "id": "dac894dd-f38d-43df-a726-c3760cf36707", "metadata": {}, "outputs": [], "source": ["function = ''\n", "for function in functions_client.list_functions(request = functions_v1.ListFunctionsRequest(parent = f'projects/{PROJECT_ID}/locations/{REGION}')):\n", "    if function.name.endswith(function_name):\n", "        break\n", "    else: function = ''"]}, {"cell_type": "code", "execution_count": 46, "id": "d7112e32-3988-4610-a3ac-c75642c98ebb", "metadata": {}, "outputs": [], "source": ["functionDef = functions_v1.CloudFunction()\n", "functionDef.name = f'projects/{PROJECT_ID}/locations/{REGION}/functions/{function_name}'\n", "functionDef.source_archive_url = f\"gs://{PROJECT_ID}/{SOURCEPATH}/function.zip\"\n", "functionDef.event_trigger = functions_v1.EventTrigger()\n", "functionDef.event_trigger.event_type = 'providers/cloud.pubsub/eventTypes/topic.publish'\n", "functionDef.event_trigger.resource = topic.name\n", "functionDef.runtime = 'python310'\n", "functionDef.entry_point = 'train'\n", "functionDef.timeout = Duration(seconds = 120)\n", "functionDef.service_account_email = SERVICE_ACCOUNT"]}, {"cell_type": "code", "execution_count": 47, "id": "1f838c1a-72fb-462e-8178-90ea694c0aed", "metadata": {}, "outputs": [{"data": {"text/plain": ["name: \"projects/statmike-mlops-349915/locations/us-central1/functions/train-05-automation\"\n", "source_archive_url: \"gs://statmike-mlops-349915/05/automation/function/function.zip\"\n", "event_trigger {\n", "  event_type: \"providers/cloud.pubsub/eventTypes/topic.publish\"\n", "  resource: \"projects/statmike-mlops-349915/topics/train-05-automation\"\n", "}\n", "entry_point: \"train\"\n", "timeout {\n", "  seconds: 120\n", "}\n", "service_account_email: \"1026793852137-compute@developer.gserviceaccount.com\"\n", "runtime: \"python310\""]}, "execution_count": 47, "metadata": {}, "output_type": "execute_result"}], "source": ["functionDef"]}, {"cell_type": "code", "execution_count": 48, "id": "8bc78600-9d8b-472d-80fe-f50408e8950f", "metadata": {}, "outputs": [{"data": {"text/plain": ["''"]}, "execution_count": 48, "metadata": {}, "output_type": "execute_result"}], "source": ["function"]}, {"cell_type": "code", "execution_count": 49, "id": "0d7d9c07-7b47-463c-b613-949ed8a6bcee", "metadata": {}, "outputs": [], "source": ["if function:\n", "    request = functions_v1.UpdateFunctionRequest(\n", "        function = functionDef\n", "    )\n", "    operation = functions_client.update_function(request = request)\n", "else:\n", "    request = functions_v1.CreateFunctionRequest(\n", "        location = f\"projects/{PROJECT_ID}/locations/{REGION}\",\n", "        function = functionDef\n", "    )\n", "    operation = functions_client.create_function(request = request)"]}, {"cell_type": "code", "execution_count": 50, "id": "bb04b527-d252-456e-81c8-c1ff07188011", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["name: \"projects/statmike-mlops-349915/locations/us-central1/functions/train-05-automation\"\n", "source_archive_url: \"gs://statmike-mlops-349915/05/automation/function/function.zip\"\n", "event_trigger {\n", "  event_type: \"providers/cloud.pubsub/eventTypes/topic.publish\"\n", "  resource: \"projects/statmike-mlops-349915/topics/train-05-automation\"\n", "  service: \"pubsub.googleapis.com\"\n", "  failure_policy {\n", "  }\n", "}\n", "status: ACTIVE\n", "entry_point: \"train\"\n", "timeout {\n", "  seconds: 120\n", "}\n", "available_memory_mb: 256\n", "service_account_email: \"1026793852137-compute@developer.gserviceaccount.com\"\n", "update_time {\n", "  seconds: 1667342811\n", "  nanos: 389000000\n", "}\n", "version_id: 1\n", "runtime: \"python310\"\n", "ingress_settings: ALLOW_ALL\n", "build_id: \"cf7df652-97b3-485a-b2a2-b759b1d6316c\"\n", "build_name: \"projects/1026793852137/locations/us-central1/builds/cf7df652-97b3-485a-b2a2-b759b1d6316c\"\n", "docker_registry: CONTAINER_REGISTRY\n", "\n"]}], "source": ["response = operation.result()\n", "print(response)"]}, {"cell_type": "code", "execution_count": 51, "id": "5d43d6a9-054c-436b-afd4-ef9cb98175c1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Review the Cloud Function in the console here:\n", "https://console.cloud.google.com/functions/list?env=gen1&project=statmike-mlops-349915\n"]}], "source": ["print(f'Review the Cloud Function in the console here:\\nhttps://console.cloud.google.com/functions/list?env=gen1&project={PROJECT_ID}')"]}, {"cell_type": "markdown", "id": "a813ea94-22c4-4bd7-8eea-5929d6698459", "metadata": {}, "source": ["---\n", "## Manual Run of Cloud Function\n", "\n", "Publish a message to the Pub/Sub topic that will cause the Cloud Function to initiate training.  The code below could be anywhere you want to trigger training!\n", "\n", "The function will receive the message as `event` in the format:\n", "```\n", "{\n", "    '@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage',\n", "    'attributes': {'key' : 'value', ...},\n", "    'data': <base64 encoded string>\n", "}\n", "```\n", "\n", "To handle the `event` and retrieve the inputs of the message three things need to happen:\n", "1. reference the 'data' value as `event['data']`\n", "2. decode the 'data' value with `base64.b64decode(<1>).decode('utf-8')`\n", "3. convert the decoded string into a Python dictionary with `json.loads(<2>)`\n", "\n", "This looks like:\n", "```\n", "funtion_inputs = json.loads(base64.b64decode(event['data']).decode('utf-8'))\n", "```"]}, {"cell_type": "code", "execution_count": 52, "id": "6ebaef20-6e01-4eaa-83f7-cb2717121684", "metadata": {}, "outputs": [], "source": ["EXPERIMENT_NAME = f'experiment-{SERIES}-05f-tf-classification-dnn'\n", "BUCKET = PROJECT_ID\n", "URI = f\"gs://{BUCKET}/{SERIES}/05f\"\n", "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{PROJECT_ID}\"\n", "\n", "function_input = {\n", "    'EPOCHS': 10,\n", "    'BATCH_SIZE': 100,\n", "    'VAR_TARGET': 'Class',\n", "    'VAR_OMIT': 'transaction_id',\n", "    'PROJECT_ID': PROJECT_ID,\n", "    'BQ_PROJECT': PROJECT_ID,\n", "    'BQ_DATASET': 'fraud',\n", "    'BQ_TABLE': 'fraud_prepped',\n", "    'REGION': REGION,\n", "    'EXPERIMENT': '05f',\n", "    'SERIES': SERIES,\n", "    'EXPERIMENT_NAME': EXPERIMENT_NAME,\n", "    'TRAIN_COMPUTE': 'n1-standard-4',\n", "    'DEPLOY_IMAGE': 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest',\n", "    'URI': URI,\n", "    'REPOSITORY': REPOSITORY,\n", "    'SERVICE_ACCOUNT': SERVICE_ACCOUNT\n", "}"]}, {"cell_type": "code", "execution_count": 53, "id": "c09e6854-2d33-48a9-9a0b-3ccb3af4ef86", "metadata": {}, "outputs": [], "source": ["message = json.dumps(function_input)\n", "message = message.encode('utf-8')"]}, {"cell_type": "code", "execution_count": 54, "id": "448b5eba-2581-4a39-8057-ab2741f4151a", "metadata": {}, "outputs": [], "source": ["future = pubsub_pubclient.publish(topic.name, message, trigger = 'manual')"]}, {"cell_type": "code", "execution_count": 55, "id": "007bb1a8-d77d-492d-973f-5f2d2cbba0ae", "metadata": {}, "outputs": [{"data": {"text/plain": ["'6140257232683221'"]}, "execution_count": 55, "metadata": {}, "output_type": "execute_result"}], "source": ["future.result()"]}, {"cell_type": "markdown", "id": "202f798b-045a-468b-810d-42009c3500f1", "metadata": {}, "source": ["---\n", "## Scheduled Run with Cloud Scheduler\n", "\n", "Use Cloud Scheduler to publish a message to the topic at any defined interval which will cause the Cloud Function to initiate training.\n", "\n", "Resources:\n", "- List of Time zones - [TZ Database Names](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)\n", "- Job Frequency - [unix-cron format guide](https://man7.org/linux/man-pages/man5/crontab.5.html)\n", "    - minute hour day_of_month month day_of_week\n", "    - 0 23 * * tue = 11PM every Tuesday\n", "\n"]}, {"cell_type": "code", "execution_count": 70, "id": "53913426-a4e6-4202-b094-b290167814fe", "metadata": {}, "outputs": [], "source": ["schedule_name = f'train-{SERIES}-{EXPERIMENT}'"]}, {"cell_type": "code", "execution_count": 71, "id": "06b236cc-6ac3-4335-8cf4-026416486cfd", "metadata": {}, "outputs": [], "source": ["schedule = ''\n", "for schedule in scheduler_client.list_jobs(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n", "    if schedule.name.endswith(schedule_name):\n", "        break\n", "    else: schedule = ''"]}, {"cell_type": "code", "execution_count": 72, "id": "15e584e7-d787-4a08-9d02-97b3029a6966", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["name: \"projects/statmike-mlops-349915/locations/us-central1/jobs/train-05-automation\"\n", "pubsub_target {\n", "  topic_name: \"projects/statmike-mlops-349915/topics/train-05-automation\"\n", "  data: \"{\\\"EPOCHS\\\": 10, \\\"BATCH_SIZE\\\": 100, \\\"VAR_TARGET\\\": \\\"Class\\\", \\\"VAR_OMIT\\\": \\\"transaction_id\\\", \\\"PROJECT_ID\\\": \\\"statmike-mlops-349915\\\", \\\"BQ_PROJECT\\\": \\\"statmike-mlops-349915\\\", \\\"BQ_DATASET\\\": \\\"fraud\\\", \\\"BQ_TABLE\\\": \\\"fraud_prepped\\\", \\\"REGION\\\": \\\"us-central1\\\", \\\"EXPERIMENT\\\": \\\"05f\\\", \\\"SERIES\\\": \\\"05\\\", \\\"EXPERIMENT_NAME\\\": \\\"experiment-05-05f-tf-classification-dnn\\\", \\\"TRAIN_COMPUTE\\\": \\\"n1-standard-4\\\", \\\"DEPLOY_IMAGE\\\": \\\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest\\\", \\\"URI\\\": \\\"gs://statmike-mlops-349915/05/05f\\\", \\\"REPOSITORY\\\": \\\"us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915\\\", \\\"SERVICE_ACCOUNT\\\": \\\"1026793852137-compute@developer.gserviceaccount.com\\\"}\"\n", "  attributes {\n", "    key: \"trigger\"\n", "    value: \"scheduled\"\n", "  }\n", "}\n", "user_update_time {\n", "  seconds: 1667343930\n", "}\n", "state: ENABLED\n", "schedule_time {\n", "  seconds: 1667358000\n", "  nanos: 106466000\n", "}\n", "schedule: \"0 23 * * tue\"\n", "time_zone: \"America/New_York\"\n", "\n"]}], "source": ["if schedule:\n", "    print(schedule)\n", "else:\n", "    request = scheduler_v1.CreateJobRequest(\n", "        parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n", "        job = scheduler_v1.Job(\n", "            name = f'projects/{PROJECT_ID}/locations/{REGION}/jobs/{schedule_name}',\n", "            pubsub_target = scheduler_v1.PubsubTarget(\n", "                topic_name = topic.name,\n", "                data = message,\n", "                attributes = {'trigger': 'scheduled'}\n", "            ),\n", "            schedule = '0 23 * * tue',\n", "            time_zone = 'America/New_York'\n", "        )\n", "    )\n", "    schedule = scheduler_client.create_job(request = request)\n", "    print(schedule)"]}, {"cell_type": "code", "execution_count": 73, "id": "e2834e9a-f5f4-4508-86b0-07d61e8ed42e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Review the Cloud Scheduler in the console here:\n", "https://console.cloud.google.com/cloudscheduler?&project=statmike-mlops-349915\n"]}], "source": ["print(f'Review the Cloud Scheduler in the console here:\\nhttps://console.cloud.google.com/cloudscheduler?&project={PROJECT_ID}')"]}], "metadata": {"environment": {"kernel": "python3", "name": "tf2-gpu.2-3.m94", "type": "gcloud", "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.12"}}, "nbformat": 4, "nbformat_minor": 5}